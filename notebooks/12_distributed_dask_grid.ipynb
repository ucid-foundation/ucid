{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Computing with Dask\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ucid-foundation/ucid/blob/main/notebooks/12_distributed_dask_grid.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "Process large-scale UCID grids using Dask for distributed computing:\n",
    "\n",
    "1. Dask DataFrame basics\n",
    "2. Parallelized UCID generation\n",
    "3. Distributed scoring\n",
    "4. Performance optimization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q ucid dask[complete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ucid\n",
    "\n",
    "print(f\"UCID version: {ucid.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Dask Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import dask.dataframe as dd\n",
    "    from dask.distributed import Client, LocalCluster\n",
    "\n",
    "    cluster = LocalCluster(n_workers=2, threads_per_worker=2)\n",
    "    client = Client(cluster)\n",
    "    print(f\"Dask dashboard: {client.dashboard_link}\")\n",
    "except ImportError:\n",
    "    print(\"Dask not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Parallel UCID Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create large dataset\n",
    "n_points = 10000\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"lat\": np.random.uniform(40.8, 41.2, n_points),\n",
    "        \"lon\": np.random.uniform(28.6, 29.4, n_points),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Created {len(df)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ddf = dd.from_pandas(df, npartitions=4)\n",
    "    print(f\"Partitions: {ddf.npartitions}\")\n",
    "except:\n",
    "    print(\"Using pandas fallback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Scaling Guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling recommendations\n",
    "scaling = {\n",
    "    \"< 10K points\": \"Single machine, pandas\",\n",
    "    \"10K - 1M points\": \"Dask LocalCluster\",\n",
    "    \"1M - 100M points\": \"Dask distributed cluster\",\n",
    "    \"> 100M points\": \"Spark or Ray cluster\",\n",
    "}\n",
    "\n",
    "print(\"Scaling Recommendations:\")\n",
    "for scale, rec in scaling.items():\n",
    "    print(f\"  {scale}: {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Key concepts:\n",
    "- Dask parallelizes pandas operations\n",
    "- Partition data for distributed processing\n",
    "- Monitor with Dask dashboard\n",
    "\n",
    "---\n",
    "\n",
    "*Copyright 2026 UCID Foundation. Licensed under EUPL-1.2.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
